{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 모음\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')\n",
    "import copy \n",
    "import os \n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import zipfile\n",
    "import timm\n",
    "\n",
    "from torchvision.models import resnet18, resnet34, resnet50\n",
    "\n",
    "from PIL import Image \n",
    "from torch.utils.data import Dataset \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms \n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau  \n",
    "import torch.nn as nn \n",
    "from torchvision import utils \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report\n",
    "import itertools \n",
    "from tqdm.notebook import trange, tqdm \n",
    "from torch import optim\n",
    "import warnings\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.visualization as vis\n",
    "import utils.transforms as tr\n",
    "import data_set.data_set as ds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "IMAGE_CHANNEL = 3\n",
    "EPOCH = 20\n",
    "batch_size = 32\n",
    "image_path = r'data\\images\\1. Training'\n",
    "label_path = r'data\\labels\\1. Training.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        # transforms.CenterCrop(IMAGE_SIZE/2),                    # 중앙에서 256x256 크기로 잘라내기\n",
    "        # transforms.RandomHorizontalFlip(p=0.5),\n",
    "        # transforms.RandomVerticalFlip(p=0.5),\n",
    "        # transforms.RandomRotation(30),\n",
    "        \n",
    "        tr.CLAHETransform(clip_limit=5.0, tile_grid_size=(8, 8)),\n",
    "        tr.GammaCorrection(gamma=0.35),\n",
    "        \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'data_set' has no attribute 'CustomImageDataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39;49mCustomImageDataset(label_path, image_path, transform\u001b[39m=\u001b[39mtransform)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'data_set' has no attribute 'CustomImageDataset'"
     ]
    }
   ],
   "source": [
    "dataset = ds.CustomImageDataset(label_path, image_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 그리드 크기 설정\n",
    "rows = 3\n",
    "vis.visualize_RGB(dataset=dataset, rows=rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size,\n",
    "                                          shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
